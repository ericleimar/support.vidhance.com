<!DOCTYPE html>
<html lang="en-us">
<head><meta charset="utf-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
<meta name="generator" content="Hugo 0.14" />
<base href="http://support.vidhance.com/">
<title> Getting Started with Vidhance SDK for Android &middot; Vidhance Support </title>
<link rel="canonical" href="http://support.vidhance.com/android/gettingstarted/">
<link rel="shortcut icon" href="/favicon.ico" type="image/vnd.microsoft.icon">

<link rel="stylesheet" href="/css/normalize.css">
<link rel="stylesheet" href="/css/text.css">
<link rel="stylesheet" href="/css/layout.css">
<link rel="stylesheet" href="/css/menu.css">
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.9.1/styles/zenburn.min.css">

</head>
<body id="inner-wrap">
	<header id="top"><a href="/"><img src="/img/logotype.png"></a>
<a id="nav-open-btn" class="nav-btn" href="#nav">Navigation</a>
</header>
	<nav id="nav">
		<div class="block">
			<ul>

	<li>
		<a href="/start/">start</a>
		
	</li>

	<li>
		<a href="/vidview/">vidview</a>
		
	</li>

	<li>
		<a href="/android/">android</a>
		<ul>

	<li>
		<a href="/android/evaluate/">evaluate</a>
		
	</li>

	<li>
		<a href="/android/gettingstarted/">getting started</a>
		
	</li>

	<li>
		<a href="/android/apireference/">API reference</a>
		
	</li>

	<li>
		<a href="/android/faq/">FAQ</a>
		
	</li>

	<li>
		<a href="/android/validate/">validate</a>
		
	</li>

</ul>

	</li>

	<li>
		<a href="/pc/">pc</a>
		<ul>

	<li>
		<a href="/pc/download/">download</a>
		
	</li>

</ul>

	</li>

</ul>

			<a id="nav-close-btn" class="close-btn" href="#top">Return to Content</a>
		</div>
	</nav>
	<main>
		<section><article
			
			>
	<header><h1>Getting Started with Vidhance SDK for Android</h1></header>
	
	
	<main>
		
			

<h1 id="introduction:4d8715ce994286818a53a9e77d960afc">Introduction</h1>

<p>This section will describe how to integrate Vidhance by wrapping the camera driver on Android devices. This can be achieved by replacing the camera HAL implementation with a wrapper which internally will link to the original implementation. This enables the wrapper to monitor the requests sent to the camera and modify the input and output data.</p>

<h1 id="prerequisites:4d8715ce994286818a53a9e77d960afc">Prerequisites</h1>

<ul>
<li>We recommend using a computer with Ubuntu 14.04</li>
<li>Android device with root access</li>
<li>Camera HAL version 1.0, 3.0 or 3.2</li>
</ul>

<h1 id="setting-up-device:4d8715ce994286818a53a9e77d960afc">Setting up device</h1>

<h2 id="enabling-usb-debugging:4d8715ce994286818a53a9e77d960afc">Enabling USB debugging</h2>

<p>You need to have USB debugging enabled on your device:</p>

<ol>
<li>Connect the device to a USB port on your computer</li>
<li>Go to the <em>Settings</em> app on your device.</li>
<li>Select <em>About phone</em></li>
<li>Tap <em>Build number</em> seven times to unlock developer options</li>
<li>You should see a message that confirms you have enabled the developer options</li>
<li>Go back to the Settings menu</li>
<li>Select <em>Developer options</em></li>
<li>Check the <em>USB debugging</em> box</li>
<li>Press OK when asked: <em>Allow USB debugging?</em></li>
<li>Press OK when asked: <em>Allow USB debugging?</em> with the computer&rsquo;s RSA key fingerprint displayed.</li>

<li><p>To verify, run the command:</p>

<pre><code class="language-sh">adb devices
</code></pre></li>

<li><p>If the device is listed as <em>device</em> you are all set. If it is listed as <em>unauthorized</em>, restart the ADB server:</p>

<pre><code class="language-sh">adb kill-server
</code></pre>

<pre><code class="language-sh">adb start-server
</code></pre>

<p>and you should be asked to allow USB debugging (see step 10).</p></li>
</ol>

<h1 id="setting-up-environment:4d8715ce994286818a53a9e77d960afc">Setting up environment</h1>

<h2 id="installing-adb:4d8715ce994286818a53a9e77d960afc">Installing ADB</h2>

<p>You will need ADB (Android Debug Bridge) to write files to the device:</p>

<pre><code class="language-sh">sudo apt-get install phablet-tools
</code></pre>

<h2 id="installing-android-ndk:4d8715ce994286818a53a9e77d960afc">Installing Android-NDK</h2>

<p>You will need ndk-build located in the Android-NDK to build the sources for your device.</p>

<ol>
<li>Download the installer <a href="https://developer.android.com/tools/sdk/ndk/index.html">here</a></li>

<li><p>Open a terminal and move to a suitable directory (e.g. home)</p>

<pre><code class="language-sh">cd ~
</code></pre></li>

<li><p>Set execution rights on the binary</p>

<pre><code class="language-sh">chmod a+x android-ndk-r10d-linux-x86_64.bin
</code></pre></li>

<li><p>Run the binary</p>

<pre><code class="language-sh">./android-ndk-r10d-linux-x86_64.bin
</code></pre></li>
</ol>

<h2 id="downloading-wrapper-sources:4d8715ce994286818a53a9e77d960afc">Downloading wrapper sources</h2>

<p>To quickly get started with Vidhance SDK we provide a public repository containing code to wrap the camera HAL and examples of how to integrate Vidhance SDK for Nexus devices. This code can easily be modified to run on your device. The repository can be cloned from github:</p>

<pre><code class="language-sh">git clone https://github.com/vidhance/android-camera-wrapper
</code></pre>

<h2 id="downloading-vidhance-library:4d8715ce994286818a53a9e77d960afc">Downloading Vidhance library</h2>

<p>Inside the nexus6 example folder you will find <em>download_vidhance.sh</em>. This script can be used to download the correct version of Vidhance for your device. You will need a key to be able to begin the download. Run the script and follow the instructions:</p>

<pre><code class="language-sh">chmod a+x download_vidhance.sh
./download_vidhance.sh
</code></pre>

<h1 id="configuring-for-your-device:4d8715ce994286818a53a9e77d960afc">Configuring for your device</h1>

<p>We recommend that you modify the example implementation for Nexus 6 to create a compatible version for your device.</p>

<h2 id="android-dependencies:4d8715ce994286818a53a9e77d960afc">Android dependencies</h2>

<p>The camera wrapper depends on libraries found in the Android source tree. We have provided the needed headers and libraries for Nexus 6 which should be compatible with any 32-bit ARM-based device running Android 5.0.1. The headers can be found in the <em>include</em> folder and the libraries in the <em>libs</em> folder. If your device uses a different architecture or Android version you may need to replace these libraries with ones compatible with your device. Contact us if you need help with this matter.</p>

<h2 id="determining-hal-version:4d8715ce994286818a53a9e77d960afc">Determining HAL version</h2>

<p>You need to know which HAL version your original library has implemented to choose the correct wrapper. Query the device with:</p>

<pre><code class="language-sh">adb shell dumpsys | grep &quot;Device version:&quot;
</code></pre>

<p>The result should be something like:</p>

<pre><code>Device version: 0x302
</code></pre>

<p>where the most significant digit is the major version number and the two least significant digits are the minor version number. In the above example the original HAL is therefore of version 3.2. Note that Vidhance SDK currently only supports HAL version 3.0 and 3.2 but support for older versions will be available soon.</p>

<h2 id="configuring-android-makefiles:4d8715ce994286818a53a9e77d960afc">Configuring Android makefiles</h2>

<h3 id="android-mk:4d8715ce994286818a53a9e77d960afc">Android.mk</h3>

<p>Inside the Nexus 6 folder you can find Android.mk which is used as a makefile when building with ndk-build. We provide wrapper implementations for a number of camera HAL versions. You need to edit the makefile to use the sources for the HAL version you intend to use with your device. In the example Android.mk you will see the sources from HAL 3 included in the makefile. Simply change the folder to the correct version.</p>

<pre><code>LOCAL_SRC_FILES := \
    ../HAL/CameraHAL.cpp \
    ../HAL/CameraWrapper.cpp \
    ../HAL/CameraWrapperFactory.cpp \
    ../HAL/HAL3/CameraHALWrapper.cpp \
    ../HAL/HAL3/VideoProcessor.cpp \
    ../vidhance/rotation_sensor/SensorReader.cpp \
    VidhanceProcessor.cpp \
LOCAL_CFLAGS += -DHAVE_PTHREADS -DHAL_3_2
</code></pre>

<h3 id="application-mk:4d8715ce994286818a53a9e77d960afc">Application.mk</h3>

<p>In this file you can specify which Android API level you are building for. A complete list can be found <a href="https://source.android.com/source/build-numbers.html">here</a>.</p>

<h2 id="changes-in-source-code:4d8715ce994286818a53a9e77d960afc">Changes in source code</h2>

<p>The VidhanceProcessor implementation in the nexus6 folder is an example of how to use the camera wrapper implementation in combination with the Vidhance library. You need some minor modifications before you start building.</p>

<h3 id="include-correct-videoprocessor-header:4d8715ce994286818a53a9e77d960afc">Include correct VideoProcessor header</h3>

<p>Make sure the correct VideoProcessor header for your HAL version is included in VidhanceProcessor.h.</p>

<pre><code>/* VidhanceProcessor.h */
#include &quot;../HAL/HAL3/VideoProcessor.h&quot;
</code></pre>

<h3 id="configure-graphicbuffer:4d8715ce994286818a53a9e77d960afc">Configure GraphicBuffer</h3>

<p>Vidhance uses Android&rsquo;s <em>GraphicBuffer</em> class to allocate buffer memory. To maximize performance, Vidhance needs to be provided with a list of widths that are aligned in memory, i.e. no padding is used. This is device-specific and needs to be explicitly provided to Vidhance. The list should contain aligned widths in bytes for GraphicBuffers allocated with format <em>HAL_PIXEL_FORMAT_RGBA_8888</em>.</p>

<h4 id="option-1:4d8715ce994286818a53a9e77d960afc">Option 1</h4>

<p>You can use the function <em>getAlignedWidth()</em> located in <em>vidhance/graphicbuffer/GraphicBufferWrapper.h</em> to check the values for your device:</p>

<pre><code>/* VidhanceProcessor.cpp */
#include &quot;../vidhance/graphicbuffer/GraphicBufferWrapper.h&quot;

vidhance_context* context = NULL;
VidhanceProcessor::VidhanceProcessor(const char* cameraId) :
		VideoProcessor(cameraId) {
	if (context == NULL) {
		aligned_width alignedWidth = getAlignedWidth();
		kean_draw_gpu_android_graphicBuffer_configureAlignedWidth(&amp;alignedWidth.width[0], alignedWidth.count);
	}
}
</code></pre>

<h4 id="option-2-recommended:4d8715ce994286818a53a9e77d960afc">Option 2 (Recommended)</h4>

<p>Option 1 should only be used to get started if you do not know the values for your device since it will slow down the initialization. The function will return the values and print the aligned widths to Logcat under the log tag <em>GraphicBufferWrapper</em> (See <a href="./android/gettingstarted#UsingDDMS">Using DDMS</a> for instructions). Use this output to create a predefined array with values. Example for Nexus 6:</p>

<pre><code>/* VidhanceProcessor.cpp */

/* Predefined aligned width in bytes for RGBA8888 GraphicBuffers on Nexus 6 */
#define ALIGNED_WIDTH_COUNT 10
const int alignedWidth[ALIGNED_WIDTH_COUNT] =
{ 128, 256, 384, 512, 1024, 1536, 2560, 3072, 3584, 4608 };

vidhance_context* context = NULL;
VidhanceProcessor::VidhanceProcessor(const char* cameraId) :
		VideoProcessor(cameraId) {
	if (context == NULL) {
		kean_draw_gpu_android_graphicBuffer_configureAlignedWidth(&amp;alignedWidth[0], ALIGNED_WIDTH_COUNT);
	}
}
</code></pre>

<p><a name="Building"></a></p>

<h1 id="building:4d8715ce994286818a53a9e77d960afc">Building</h1>

<p>The <em>make.sh</em> script is an example of how to use ndk-build to build the sources. You are of course free to use your toolchain of choice. The build should generate <em>libcamera_wrapper.so</em>.</p>

<p><a name="PreparingPhoneForWrapper"></a></p>

<h1 id="preparing-phone-for-wrapper:4d8715ce994286818a53a9e77d960afc">Preparing phone for wrapper</h1>

<p>Before we can push the wrapper to the device we need to know the filename Android expects when loading the camera HAL. For example, for Nexus 5 it is <em>camera.hammerhead.so</em> and for Nexus 6
<em>camera.msm8084.so</em>. What we want to do is to rename the wrapper library to the expected filename and rename the actual HAL implementation to camera_backend.so so it can be loaded by the wrapper.</p>

<p>It is recommended to create a backup of the original HAL implementation if you somehow manage to delete it by mistake. You can pull the library from the device with adb:</p>

<pre><code>adb pull /system/lib/hw/camera.msm8084.so &lt;path on your computer&gt;
</code></pre>

<p>First take a look at the setup_device.sh script which demonstrates how to create the backend library from the default HAL implementation. Make sure you set the <em>CAMERA_HAL</em> variable to the name of your original library. The script also pushes the Vidhance library to the phone so make sure you have downloaded it and specified the correct path to it in the script. Once the script has completed you don&rsquo;t have to run it unless you reinstall Android on your phone or simply want to push a newer version of the Vidhance library.</p>

<pre><code>#setup_device.sh

#!/bin/bash
CAMERA_HAL=camera.msm8084.so
VIDHANCE_PATH=./libs/libvidhance_android32.so
../scripts/setup_device.sh $CAMERA_HAL $VIDHANCE_PATH

</code></pre>

<p><a name="PushingToPhone"></a></p>

<h1 id="pushing-to-phone:4d8715ce994286818a53a9e77d960afc">Pushing to phone</h1>

<p>Every time you have rebuilt the wrapper library you can use the push.sh script to overwrite it on the device. Make sure you set the <em>CAMERA_HAL</em> variable to the name of your original library and the correct path to your wrapper library.</p>

<pre><code>#push.sh

#!/bin/bash
CAMERA_HAL=camera.msm8084.so
WRAPPER_PATH=./libs/armeabi-v7a/libcamera_wrapper.so
../scripts/push.sh $CAMERA_HAL $WRAPPER_PATH

</code></pre>

<h1 id="using-the-vidhance-api:4d8715ce994286818a53a9e77d960afc">Using the Vidhance API</h1>

<p>Examine the <em>VidhanceProcessor</em> implementation in the nexus6 folder and use it as a tutorial of how to integrate Vidhance for Android. Here is a more detailed description of the code:</p>

<h2 id="initializing:4d8715ce994286818a53a9e77d960afc">Initializing</h2>

<p>Before you can use the Vidhance API you need to initialize it by calling the load function:</p>

<pre><code>vidhance_load();
</code></pre>

<h2 id="register-callbacks:4d8715ce994286818a53a9e77d960afc">Register callbacks</h2>

<h3 id="graphicbuffer:4d8715ce994286818a53a9e77d960afc">GraphicBuffer</h3>

<p>Vidhance depends on a number of callbacks to interact with Android&rsquo;s GraphicBuffer. These callbacks are located in the vidhance folder and should <strong>NOT</strong> be modified. Simply include the header and supply Vidhance with the function pointers.</p>

<pre><code>#include &quot;../vidhance/graphicbuffer/GraphicBufferWrapper.h&quot;
</code></pre>

<pre><code>kean_draw_gpu_android_graphicBuffer_registerCallbacks(
  allocateGraphicBuffer,
  createGraphicBuffer,
  freeGraphicBuffer,
  lockGraphicBuffer,
  unlockGraphicBuffer);
</code></pre>

<p><a name="DebugPrint"></a></p>

<h3 id="debug-print:4d8715ce994286818a53a9e77d960afc">Debug print</h3>

<p>If you want debug output from Vidhance you can register a print callback. A default function that prints to logcat is located in the vidhance folder but you are free to use your own.</p>

<pre><code>#include &quot;../vidhance/debug/Debug.h&quot;
</code></pre>

<pre><code>kean_base_debug_registerCallback(debugPrint);
</code></pre>

<h2 id="creating-vidhance-context:4d8715ce994286818a53a9e77d960afc">Creating Vidhance context</h2>

<p>To create a context we first need to create settings for the context.</p>

<pre><code>vidhance_settings* settings = vidhance_settings_new();
</code></pre>

<p>If your device can provide rotational sensor data you should register the getRotationVector callback in the settings. Include the header in the vidhance folder and register the function pointer.</p>

<pre><code>#include &quot;../vidhance/rotation_sensor/RotationSensor.h&quot;
</code></pre>

<pre><code>vidhance_settings_registerCallback(settings, getRotationVector);
</code></pre>

<p>We can now create a vidhance context using the settings. It is recommended to store the context statically to prevent the need to construct it every time the camera starts.</p>

<pre><code>vidhance_context* context = NULL;
VidhanceProcessor::VidhanceProcessor(const char* cameraId) :
		VideoProcessor(cameraId) {
...
if (context == NULL)
  context = vidhance_context_new(settings);
}
</code></pre>

<h2 id="processing-frames:4d8715ce994286818a53a9e77d960afc">Processing frames</h2>

<p>The VidhanceProcessor contains one callback for video capture buffers and one for preview buffers. To feed a frame to the Vidhance context, an image object needs to be created from some of the properties of the GraphicBuffer parameter. The object needs to know how the data in the buffer is aligned in memory. For example, for Nexus 6 the width of the frame will be padded to 64 byte alignment and the height to 32 byte alignment.</p>

<p>The image structure can then be passed to one of the process functions. The first argument will be used as input buffer and the second argument will be used as output buffer where the result is written.</p>

<pre><code>void VidhanceProcessor::processVideoCapture(sp&lt;GraphicBuffer&gt; input, sp&lt;GraphicBuffer&gt; output) {
	int horizontalStride = ALIGN(input-&gt;width, 64);
	int verticalStride = ALIGN(input-&gt;height, 32);
	int uvOffset = horizontalStride * verticalStride;
	kean_draw_gpu_android_graphicBufferYuv420Semiplanar* inputImage = kean_draw_gpu_android_graphicBufferYuv420Semiplanar_new((void*)input.get(),
			(void*)input-&gt;getNativeBuffer(), (void*) input-&gt;handle,
			kean_math_intSize2D_new(input-&gt;width, input-&gt;height), horizontalStride, input-&gt;format, uvOffset);
	kean_draw_gpu_android_graphicBufferYuv420Semiplanar* outputImage = kean_draw_gpu_android_graphicBufferYuv420Semiplanar_new((void*)output.get(),
			(void*)output-&gt;getNativeBuffer(), (void*) output-&gt;handle,
			kean_math_intSize2D_new(output-&gt;width, output-&gt;height), horizontalStride, output-&gt;format, uvOffset);
	vidhance_context_process(context, (kean_draw_image*) inputImage, (kean_draw_image*) outputImage);
}
</code></pre>

<h2 id="configuring-settings:4d8715ce994286818a53a9e77d960afc">Configuring settings</h2>

<p>It is recommended to use the default settings until you have successfully built and pushed to the device. The Vidhance API enables you to configure the settings of the different modules to optimize quality and performance for your device. Take a look in <em>vidhance.h</em> to see the available settings. As an example we will look at the motion settings:</p>

<pre><code>/* Motion Settings */
vidhance_motion_settings* vidhance_settings_getMotion(vidhance_settings* settings);
void vidhance_motion_settings_setComplexity(vidhance_motion_settings* settings, int complexity);
int vidhance_motion_settings_getComplexity(vidhance_motion_settings* settings);
void vidhance_motion_settings_setMode(vidhance_motion_settings* settings, vidhance_motion_mode mode);
vidhance_motion_mode vidhance_motion_settings_getMode(vidhance_motion_settings* settings);
</code></pre>

<p>First we need a reference to the motion settings from our base settings:</p>

<pre><code>vidhance_settings* settings = vidhance_settings_new();
vidhance_motion_settings* motionSettings = vidhance_settings_getMotion(settings);
</code></pre>

<p>Then we can alter a setting for this settings object:</p>

<pre><code>vidhance_motion_settings_setComplexity(motionSettings, 3);
</code></pre>

<p>Finally we create the Vidhance context with the base settings object:</p>

<pre><code>context = vidhance_context_new(settings);
</code></pre>

<h1 id="running:4d8715ce994286818a53a9e77d960afc">Running</h1>

<h2 id="instructions:4d8715ce994286818a53a9e77d960afc">Instructions</h2>

<ol>
<li>Make sure you have successfully executed the <em>setup_device.sh</em> script so the backend library and the Vidhance library exist on the device. (See <a href="./android/gettingstarted#PreparingPhoneForWrapper">Preparing phone for wrapper</a>)</li>
<li>Build your implementation. (See <a href="./android/gettingstarted#Building">Building</a>)</li>
<li>Push the wrapper to the device. (See <a href="./android/gettingstarted#PushingToPhone">Pushing to phone</a>)</li>
<li>When the device has rebooted you can use any camera app on the device to view your results.</li>
</ol>

<h2 id="what-to-expect:4d8715ce994286818a53a9e77d960afc">What to expect</h2>

<p>If you have successfully built and pushed the correct files to your device you should be able to notice modifications in both the preview and captured video. If you used the default settings when creating the Vidhance context you can expect to see the following:</p>

<ul>
<li>The preview should have a clearly visible viewfinder</li>
<li>The captured video should be stabilized with a cleary visible motion trace in the lower right corner</li>
</ul>

<p>If your result is not as expected you can proceed to the next chapter or contact our support via the chat widget on this page.</p>

<h1 id="troubleshooting:4d8715ce994286818a53a9e77d960afc">Troubleshooting</h1>

<p>It is recommended to use the debug version of the Vidhance library while in development. Version can be selected when running the <em>download_vidhance.sh</em> script. The debug version includes useful print output which can be captured by configuring the debugPrint callback to a function of your choice (see <a href="./android/gettingstarted#DebugPrint">Debug print</a>).
<a name="UsingDDMS"></a></p>

<h2 id="using-ddms:4d8715ce994286818a53a9e77d960afc">Using DDMS</h2>

<p>The default callback for output is located in <em>vidhance/debug/Debug.h</em> and will print the output to Android&rsquo;s logging system Logcat. This output can be captured by using DDMS (Dalvik Debug Monitor Server) which is included in the Android-SDK. Follow these steps:</p>

<ol>
<li>Download Android-SDK <a href="http://developer.android.com/sdk/index.html">here</a></li>
<li>Run <em>ddms</em> located in <em>android-sdks/tools</em></li>
<li>Make sure your device is connected by USB and with USB debugging enabled. You should see your device listed in the DDMS window.</li>

<li><p>Create a new filter with these settings:</p>

<ul>
<li><em>Filter Name:</em> Vidhance</li>
<li><em>by Log Tag:</em> Vidhance</li>
<li><em>by Log Level:</em> verbose</li>
<li>Leave the rest blank.</li>
</ul></li>

<li><p>You should now get output to the filter from the Vidhance library when your device is capturing video.</p></li>

<li><p>If you have problems with crashes it can be helpful to get the backtrace from the device. Create another filter with these settings:</p>

<ul>
<li><em>Filter Name:</em> Debug</li>
<li><em>by Log Tag:</em> DEBUG</li>
<li><em>by Log Level:</em> verbose</li>
<li>Leave the rest blank.</li>
</ul></li>

<li><p>When the device crashes you can check the backtrace in the debug filter for useful information.</p></li>
</ol>

		
		</main>
	<footer></footer>
</article>
</section>
	</main>
	<footer>		<p>copyright &copy; Imint Image Intelligence AB</p>
</footer>
	<script src="http://code.jquery.com/jquery-1.11.3.min.js"></script>
<script src="/script/doubleTapToGo.js"></script>
<script src="/script/modernizr.js"></script>
<script src="/script/main.js"></script>
<script>
	$(document).ready(function() {
		$('nav li:has(ul)').doubleTapToGo();
		
	})
</script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.9.1/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>
<script>
$('#downloadForm').on('submit', function(e) {
	key = $("input:first").val();
	url = "https://aurora.imint.se/data/"+key+"/vidhance-sdk-pc/vidhance_0.7.0_32bit.zip";
	$('#hiddenIFrame').attr("src", url);
	return false;
});

var $_Tawk_API={},$_Tawk_LoadStart=new Date();
(function(){
var s1=document.createElement("script"),s0=document.getElementsByTagName("script")[0];
s1.async=true;
s1.src='https://embed.tawk.to/550802b2059b265f5423f78e/default';
s1.charset='UTF-8';
s1.setAttribute('crossorigin','*');
s0.parentNode.insertBefore(s1,s0);
})();
</script>


</body>
</html>
